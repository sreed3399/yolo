{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup / Verify CUDA working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7263, 0.2070, 0.0866],\n",
      "        [0.8521, 0.4276, 0.2423],\n",
      "        [0.0149, 0.1014, 0.6648],\n",
      "        [0.8903, 0.2924, 0.5150],\n",
      "        [0.1389, 0.4584, 0.2102]])\n"
     ]
    }
   ],
   "source": [
    "# Validate Torch is installed. Should see a matrix of tensors \n",
    "# tensor([[0.3380, 0.3845, 0.3217], etc etc\n",
    "        \n",
    "\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU detected: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU detected:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu124\n",
      "CUDA version: 12.4\n",
      "ID of current CUDA device:0\n",
      "Name of current CUDA device:NVIDIA GeForce RTX 4060 Ti\n",
      "Torch version: 2.5.1+cu124\n",
      "cudnn: True\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "print(f'Torch version: {torch.__version__}')\n",
    "print(f'CUDA version: {torch.version.cuda}')\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")\n",
    "print(f'Torch version: {torch.__version__}')\n",
    "print(f'cudnn: {torch.backends.cudnn.enabled}')\n",
    "\n",
    "\n",
    "#yolo task=detect mode=train model=yolo516u.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = YOLO(\"yolov8x\")\n",
    "#model = YOLO(\"yolov10-x\")\n",
    "model = YOLO('yolo11n.pt')\n",
    "model.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'c:/coding/yolo/media/celtics-short.mp4'\n",
    "file = 'c:/coding/yolo/media/pic1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11n.pt\")\n",
    "results = model(file, stream=True)\n",
    "\n",
    "print(type(results))  # Check the output type\n",
    "print(results)  \n",
    "\n",
    "for r in results:\n",
    "    r.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#results = model.track(source=file, stream=True)\n",
    "results = model(file)\n",
    "print(type(results))  # Check the output type\n",
    "print(results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(source=file, stream=False)\n",
    "print(type(results))  # Check the output type\n",
    "print(results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLO11 model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Specify the source image\n",
    "source = \"https://ultralytics.com/images/bus.jpg\"\n",
    "\n",
    "# Make predictions\n",
    "results = model.predict(source, save=True, imgsz=320, conf=0.5)\n",
    "\n",
    "# Extract bounding box dimensions\n",
    "boxes = results[0].boxes.xywh.cpu()\n",
    "for box in boxes:\n",
    "    x, y, w, h = box\n",
    "    print(f\"Width of Box: {w}, Height of Box: {h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from roboflow import Roboflow\n",
    "#rf = Roboflow(api_keys='apikey')\n",
    "#project = rf.workspace('viren-dhanwani').project(\"tennis-ball-detection\")\n",
    "#version = project.version(6)\n",
    "#dataset = version.download(\"yolov5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
